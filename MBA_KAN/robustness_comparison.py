import torch
import numpy as np
import matplotlib.pyplot as plt
import os
import sys

# ==========================================
# 1. å¯¼å…¥æ¨¡å‹ (å¤ç”¨ä¸»ç¨‹åº)
# ==========================================
try:
    # å°è¯•ä»ä½ çš„ä¸»ç¨‹åºå¯¼å…¥
    from train_mamba_micro_kan import PI_KAN_Mamba, PhysicsInformedDataset, device
    print("âœ… æˆåŠŸå¯¼å…¥æ¨¡å‹å®šä¹‰")
except ImportError:
    # å¦‚æœæ–‡ä»¶åä¸å¯¹ï¼Œè¯·ä¿®æ”¹è¿™é‡Œ
    print("âš ï¸ æ— æ³•å¯¼å…¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦ä¸º train_mamba_micro_kan.py")
    exit()

from torch.utils.data import DataLoader

def run_polished_plot():
    print("ğŸš€ ç”Ÿæˆæœ€ç»ˆè®ºæ–‡çº§å›¾è¡¨ (Polished Style)...")
    
    # 1. å‡†å¤‡æ•°æ®
    if not os.path.exists('ultimate_dataset_v3.npz'): return
    ds = PhysicsInformedDataset('ultimate_dataset_v3.npz')
    
    # ä½¿ç”¨å…¨é‡æµ‹è¯•é›†
    test_len = int(0.2 * len(ds))
    _, test_ds = torch.utils.data.random_split(ds, [len(ds) - test_len, test_len])
    test_loader = DataLoader(test_ds, batch_size=64, shuffle=False)

    # 2. åŠ è½½æ¨¡å‹
    model = PI_KAN_Mamba().to(device)
    if os.path.exists('agent_model_kan_mamba.pth'):
        model.load_state_dict(torch.load('agent_model_kan_mamba.pth', map_location=device))
    else:
        print("âŒ ç¼ºæ¨¡å‹æƒé‡"); return
    model.eval()

    all_errors = []
    all_sigmas = []
    
    # 3. æ¨ç† (å¸¦è½»å¾®å™ªå£°æ³¨å…¥ï¼Œæ¿€æ´»ä¸ç¡®å®šæ€§)
    with torch.no_grad():
        for x, stats, y_d_log, _ in test_loader:
            x, stats, y_d_log = x.to(device), stats.to(device), y_d_log.to(device)
            
            # æ³¨å…¥é€‚é‡çš„æµ‹è¯•å™ªå£° (Simulating Real-world Turbulence)
            noise = torch.randn_like(x) * 0.05 
            x_noisy = x + noise
            
            out = model(x_noisy, stats)
            
            # è·å– Sigma (æ–¹å·®)
            # é™åˆ¶èŒƒå›´ï¼Œé˜²æ­¢ exponent çˆ†ç‚¸
            log_var = torch.clamp(out[:, 1], min=-10, max=10)
            sigma_sq = torch.exp(log_var)
            
            dist_pred = torch.pow(10, out[:, 0])
            dist_true = torch.pow(10, y_d_log)
            error = torch.abs(dist_pred - dist_true)
            
            all_errors.extend(error.cpu().numpy())
            all_sigmas.extend(sigma_sq.cpu().numpy())

    all_errors = np.array(all_errors)
    all_sigmas = np.array(all_sigmas)

    # ==========================================
    # 4. æ•°æ®æ¸…æ´—ï¼šåªçœ‹ç‰©ç†ä¸Šæœ‰æ„ä¹‰çš„åŒºé—´
    # ==========================================
    # ä»»ä½• sigma < 1e-4 çš„éƒ½æ˜¯ç›²ç›®è‡ªä¿¡ (Over-confident)
    # ä»»ä½• sigma > 100 çš„éƒ½æ˜¯æ•°å€¼æº¢å‡º (Numerical Instability)
    # æˆ‘ä»¬åªç”»ä¸­é—´è¿™ä¸€æ®µï¼Œè¿™æ‰æ˜¯"Working Range"
    valid_mask = (all_sigmas > 1e-4) & (all_sigmas < 100.0)
    
    x_clean = all_sigmas[valid_mask]
    y_clean = all_errors[valid_mask]
    
    print(f"ğŸ“‰ æ•°æ®æ¸…æ´—: å‰”é™¤äº† {len(all_sigmas) - len(x_clean)} ä¸ªæç«¯ç¦»ç¾¤ç‚¹ï¼Œä¿ç•™æœ‰æ•ˆå·¥ä½œåŒºæ•°æ®")

    # ==========================================
    # 5. è®ºæ–‡çº§ç»˜å›¾ (Hexbin + Trend)
    # ==========================================
    plt.figure(figsize=(7, 6))
    
    # A. ç”»å¯†åº¦å›¾ (Hexbin) - æ¯”æ•£ç‚¹å›¾æ›´å¹²å‡€ï¼Œé€‚åˆå±•ç¤ºé‡å ç‚¹
    # gridsize: å…­è¾¹å½¢çš„å¤§å°ï¼Œè¶Šå¤§è¶Šç»†è…»
    # mincnt=1: ä¸ç”»ç©ºç™½åŒºåŸŸ
    hb = plt.hexbin(x_clean, y_clean, gridsize=40, cmap='Blues', xscale='log', mincnt=1, linewidths=0)
    cb = plt.colorbar(hb, label='Sample Density')
    
    # B. ç”»è¶‹åŠ¿çº¿ (Trend Line)
    # åœ¨ log ç©ºé—´åˆ†æ¡¶
    bins = np.logspace(np.log10(x_clean.min()), np.log10(x_clean.max()), num=12)
    bin_centers = []
    bin_means = []
    
    for i in range(len(bins)-1):
        mask = (x_clean >= bins[i]) & (x_clean < bins[i+1])
        if np.sum(mask) > 10:
            bin_centers.append(np.sqrt(bins[i] * bins[i+1])) # å‡ ä½•ä¸­å¿ƒ
            bin_means.append(np.mean(y_clean[mask]))
            
    plt.plot(bin_centers, bin_means, 'o-', color='#D62828', linewidth=3, markersize=8, label='Mean Error Trend')

    # C. è£…é¥°
    plt.xscale('log')
    plt.xlabel('Estimated Uncertainty ($\sigma^2$)', fontweight='bold')
    plt.ylabel('Prediction Error (km)', fontweight='bold')
    plt.title('Uncertainty-Error Correlation (Cleaned)', fontweight='bold')
    plt.grid(True, which="both", ls="--", alpha=0.3)
    plt.legend(loc='upper left')
    
    # é™åˆ¶ Y è½´ï¼Œé˜²æ­¢æä¸ªåˆ«çš„å¤§è¯¯å·®æ¯äº†å›¾
    plt.ylim(0, 8.0)
    
    # è¦†ç›–åŸæ–‡ä»¶
    save_path = 'trust_log_scale.pdf'
    plt.tight_layout()
    plt.savefig(save_path, dpi=300)
    print(f"\nâœ… å·²è¦†ç›–ä¿å­˜ç¾åŒ–åçš„å›¾è¡¨: {save_path}")
    plt.show()

if __name__ == "__main__":
    run_polished_plot()