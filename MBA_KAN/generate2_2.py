import numpy as np
import pandas as pd
from scipy.interpolate import interp1d
import os
import pickle
from tqdm import tqdm


class RobustUSVSimulator:
    """
    [ç§‘ç ”ç‰ˆ v3.0] é¢å‘æ— äººèˆ¹æº¯æºçš„é²æ£’æ€§æ•°æ®ç”Ÿæˆå™¨
    - é›†æˆçœŸå®æ°´è´¨èƒŒæ™¯ (Station Time Series)
    - ç‰©ç†å¢å¼ºçš„ADEæ‰©æ•£æ¨¡å‹ (Physics-Informed)
    - æ¨¡æ‹Ÿéç†æƒ³ä¼ æ„Ÿå™¨ç‰¹æ€§ (Sensor Noise & Failure)
    """

    def __init__(self, pkl_path='station_time_series.pkl', rng_seed=42):
        self.generated_data = []
        np.random.seed(rng_seed)
        self.pkl_path = pkl_path

        # 1. åŠ è½½çœŸå®èƒŒæ™¯åº“
        if os.path.exists(self.pkl_path):
            print(f"ğŸ“š æ­£åœ¨åŠ è½½çœŸå®èƒŒæ™¯åº“: {self.pkl_path} ...")
            with open(self.pkl_path, 'rb') as f:
                self.station_data = pickle.load(f)
            self.station_names = list(self.station_data.keys())
            print(f"âœ… åŠ è½½æˆåŠŸï¼å¯ç”¨ç«™ç‚¹æ•°: {len(self.station_names)}")
        else:
            print(f"âŒ è­¦å‘Š: æœªæ‰¾åˆ° {self.pkl_path}")
            print("   è¯·å…ˆè¿è¡Œ 'æ•°æ®é‡ç»„è„šæœ¬.py' ç”ŸæˆèƒŒæ™¯åº“ï¼Œå¦åˆ™å°†ä½¿ç”¨çº¯éšæœºå™ªå£°èƒŒæ™¯ã€‚")
            self.station_names = []

    def _get_background_segment(self, duration_hours=24, dt_minutes=1):
        """
        ä»çœŸå®æ•°æ®ä¸­æå–ä¸€æ®µèƒŒæ™¯ï¼Œå¹¶æ’å€¼åˆ° 1åˆ†é’Ÿ/ç‚¹ çš„é«˜åˆ†è¾¨ç‡
        """
        # å¦‚æœæ²¡æœ‰çœŸå®æ•°æ®ï¼Œç”Ÿæˆçº¯éšæœºå™ªå£° (Fallback)
        if not self.station_names:
            t_target = np.arange(0, duration_hours, dt_minutes / 60.0)
            # æ¨¡æ‹Ÿ: COD=4.0, pH=7.5, DO=8.0, Temp=20.0
            base = np.array([4.0, 7.5, 8.0, 20.0])
            noise = np.random.normal(0, [0.5, 0.1, 0.5, 1.0], size=(len(t_target), 4))
            return t_target, base + noise

        # å°è¯•æå–çœŸå®ç‰‡æ®µ
        for _ in range(10):
            try:
                name = np.random.choice(self.station_names)
                data = self.station_data[name]  # [Time, COD, pH, DO, Temp]

                # éœ€è¦çš„ç‚¹æ•° (åŸæ•°æ®çº¦15-30minä¸€ä¸ªç‚¹ï¼Œéœ€ä¿è¯åŸæ•°æ®å¤Ÿé•¿)
                min_points = int(duration_hours * 2) + 5
                if len(data) < min_points: continue

                # éšæœºæˆªå–
                max_idx = len(data) - min_points
                start_idx = np.random.randint(0, max_idx)
                segment = data[start_idx: start_idx + min_points]

                # æ—¶é—´å¤„ç†ä¸å»é‡
                t_objs = pd.to_datetime(segment[:, 0])
                t_relative = (t_objs - t_objs[0]).total_seconds() / 3600.0
                values = segment[:, 1:].astype(float)

                # ç®€å•æ¸…æ´— NaN
                if np.isnan(values).any():
                    col_mean = np.nanmean(values, axis=0)
                    inds = np.where(np.isnan(values))
                    values[inds] = np.take(col_mean, inds[1])

                # æ’åºä¸å»é‡ (é˜²æ­¢ interp1d æŠ¥é”™)
                _, unique_indices = np.unique(t_relative, return_index=True)
                if len(unique_indices) < 5: continue

                t_relative = t_relative[unique_indices]
                values = values[unique_indices]

                # çº¿æ€§æ’å€¼åˆ°ç›®æ ‡åˆ†è¾¨ç‡ (ä¾‹å¦‚ 1åˆ†é’Ÿ)
                f_interp = interp1d(t_relative, values, axis=0, kind='linear', fill_value="extrapolate")
                t_target = np.arange(0, duration_hours, dt_minutes / 60.0)
                bg_interpolated = f_interp(t_target)

                # ç‰©ç†çº¦æŸ: COD, DO ä¸èƒ½å°äº 0.1
                bg_interpolated[:, 0] = np.maximum(bg_interpolated[:, 0], 0.1)
                bg_interpolated[:, 2] = np.maximum(bg_interpolated[:, 2], 0.1)

                return t_target, bg_interpolated

            except Exception:
                continue

        # å¦‚æœå¤šæ¬¡å¤±è´¥ï¼Œè¿”å›é»˜è®¤å™ªå£°
        return self._get_background_segment(duration_hours, dt_minutes)

    @staticmethod
    def _apply_sensor_imperfections(sequences, drop_prob=0.05, outlier_prob=0.01):
        """
        [å…³é”®] æ¨¡æ‹Ÿéç†æƒ³ä¼ æ„Ÿå™¨æ•°æ® (Robustness)
        """
        cod, ph, do, vel = sequences
        seq_len = len(cod)

        # 1. æ¨¡æ‹Ÿä¸¢åŒ… (Dropouts): æŸæ®µæ—¶é—´ä¼ æ„Ÿå™¨è¯»æ•°ä¸º0æˆ–å¡æ­»
        if np.random.random() < 0.15:  # 15% æ¦‚ç‡å‡ºç°ä¸¢åŒ…
            drop_len = np.random.randint(2, 6)  # ä¸¢ 2-6 åˆ†é’Ÿ
            if seq_len > drop_len:
                start = np.random.randint(0, seq_len - drop_len)
                # æ¨¡æ‹Ÿä¼ æ„Ÿå™¨è¾“å‡ºå½’é›¶
                cod[start: start + drop_len] = 0.01

                # 2. æ¨¡æ‹Ÿæ¯›åˆº (Outliers): æ°´è‰ç¼ ç»•ã€æ°”æ³¡ç­‰
        # éšæœºé€‰æ‹© 1% çš„ç‚¹å˜æˆå¼‚å¸¸å€¼
        mask_outlier = np.random.rand(seq_len) < outlier_prob
        noise_spike = np.random.choice([20.0, -10.0], size=mask_outlier.sum())
        cod[mask_outlier] += noise_spike

        # 3. æ¨¡æ‹Ÿé‡ç¨‹é¥±å’Œ (Saturation): å‡è®¾ä»ªå™¨ä¸Šé™åœ¨ 80-150 ä¹‹é—´æ³¢åŠ¨
        saturation_limit = np.random.uniform(80, 150)
        cod = np.clip(cod, a_min=None, a_max=saturation_limit)

        # 4. æ¨¡æ‹Ÿé«˜æ–¯ç™½å™ªå£° (ä»ªå™¨åº•å™ª)
        cod += np.random.normal(0, 0.1, seq_len)
        ph += np.random.normal(0, 0.02, seq_len)
        do += np.random.normal(0, 0.05, seq_len)

        return [cod, ph, do, vel]

    def solve_ade(self, t_hours, distance_m, mass_mg, U, Q, D, k):
        """ä¸€ç»´ ADE è§£æè§£"""
        A = Q / U
        if distance_m < 10: distance_m = 10.0

        # è½¬æ¢å•ä½
        t_seconds = t_hours * 3600.0
        t_seconds[t_seconds < 1.0] = 1.0  # é˜²æ­¢é™¤é›¶
        k_s = k / 86400.0

        term1 = mass_mg / (A * np.sqrt(4 * np.pi * D * t_seconds))
        exponent = -((distance_m - U * t_seconds) ** 2) / (4 * D * t_seconds) - k_s * t_seconds
        return term1 * np.exp(exponent)

    def generate_dataset(self, n_samples=5000, obs_window_min=30):
        """ä¸»ç”Ÿæˆå¾ªç¯ (ä¿®æ­£ç‰ˆï¼šå¼ºåˆ¶é«˜ä¿¡å™ªæ¯”)"""
        self.generated_data = []
        print(f"ğŸš€ å¼€å§‹ç”Ÿæˆæ•°æ®é›† (ä¿®æ­£ç‰ˆ - ä¿è¯æ³¢å½¢å¯è§)...")

        pbar = tqdm(total=n_samples)

        while len(self.generated_data) < n_samples:
            # 1. è·å–èƒŒæ™¯
            try:
                t_axis, bg_matrix = self._get_background_segment(duration_hours=24, dt_minutes=1)
            except:
                continue

            # è®¡ç®—èƒŒæ™¯å™ªå£°æ°´å¹³ (æ ‡å‡†å·®)
            bg_cod_base = np.mean(bg_matrix[:, 0])
            bg_noise_std = np.std(bg_matrix[:, 0])
            # é˜²æ­¢èƒŒæ™¯å¤ªå¹²å‡€å¯¼è‡´é™¤é›¶ï¼Œè®¾ç½®æœ€å°å™ªå£°åŸºå‡†
            bg_noise_std = max(bg_noise_std, 0.1)

            # 2. éšæœºæ°´åŠ›å‚æ•°
            U = np.random.uniform(0.3, 1.2)
            U_dynamic = U + np.sin(np.linspace(0, 10, len(t_axis))) * 0.05

            width = np.random.uniform(20, 100)
            depth = np.random.uniform(1.5, 5.0)
            Q = width * depth * U

            # æ‰©æ•£ç³»æ•° D (ç¨å¾®å‡å°ä¸€ç‚¹ä¸Šé™ï¼Œé˜²æ­¢ç¨€é‡Šå¤ªå¿«)
            D = np.random.uniform(0.3, 1.0) * U * width

            # 3. æ±¡æŸ“æºè®¾å®š (å¤§å¹…æå‡æºå¼ºä¸Šé™ï¼Œä¿è¯è¿œåœºèƒ½çœ‹åˆ°)
            # æ—§èŒƒå›´: 5000~60000 -> æ–°èŒƒå›´: 20000~200000 mg/L
            source_conc = np.random.uniform(20000, 200000)
            # æ—§ä½“ç§¯: 10~80 -> æ–°ä½“ç§¯: 50~150 m3
            vol_m3 = np.random.uniform(50, 150)
            mass_mg = source_conc * vol_m3 * 1000

            dist_km = np.random.uniform(2.0, 50.0)
            dist_m = dist_km * 1000

            # 4. è®¡ç®— ADE
            temp = np.mean(bg_matrix[:, 3])
            k_val = 0.2 * (1.047 ** (temp - 20))  # ç¨å¾®é™ä½è¡°å‡ç³»æ•° kï¼Œè®©æ±¡æŸ“ç‰©å­˜æ´»æ›´ä¹…

            pollutant_curve = self.solve_ade(t_axis, dist_m, mass_mg, U, Q, D, k_val)

            peak_val = np.max(pollutant_curve)

            # =======================================================
            # ğŸ”¥ æ ¸å¿ƒä¿®æ­£ï¼šä¿¡å™ªæ¯”æ£€æŸ¥ (SNR Check)
            # =======================================================
            # åªæœ‰å½“æ±¡æŸ“å³°å€¼ æ˜¾è‘—é«˜äº èƒŒæ™¯å™ªå£° (ä¾‹å¦‚ 5å€æ ‡å‡†å·®) æ—¶æ‰ä¿ç•™
            # å¹¶ä¸”å³°å€¼ç»å¯¹æµ“åº¦è‡³å°‘è¦æœ‰ 2.0 mg/L (é˜²æ­¢æ•°å€¼å¤ªå°)
            if peak_val < 2.0 or peak_val < bg_noise_std * 5.0:
                continue  # ä¿¡å·å¤ªå¼±ï¼Œé‡å¼€

            # 5. ç¡®å®šæœ‰æ•ˆè§‚æµ‹åŒºé—´
            # é˜ˆå€¼è®¾ä¸ºå³°å€¼çš„ 5%ï¼Œæˆ–è€…æ˜¯èƒŒæ™¯å™ªå£°çš„ 2å€ï¼Œå–å¤§è€…
            # è¿™æ ·ä¿è¯æˆ‘ä»¬åœ¨æ³¢å½¢çš„â€œå±±è„šä¸‹â€ä¹Ÿèƒ½æˆªå–åˆ°æ•°æ®ï¼Œè€Œä¸æ˜¯åªåœ¨å±±é¡¶
            threshold = max(peak_val * 0.05, bg_noise_std * 2.0)

            valid_indices = np.where(pollutant_curve > threshold)[0]
            if len(valid_indices) < obs_window_min:
                continue

            plume_start = valid_indices[0]
            plume_end = valid_indices[-1]
            plume_duration = plume_end - plume_start

            # æ‰©å¤§é‡‡æ ·èŒƒå›´ï¼Œå…è®¸æ™ºèƒ½ä½“çœ‹åˆ°ä» "åˆšèµ·æ­¥" åˆ° "æ‹–å°¾ç»“æŸ"
            safe_start = max(0, plume_start - 20)
            safe_end = min(len(t_axis) - obs_window_min, plume_end + 60)

            if safe_end <= safe_start: continue

            agent_start_idx = np.random.randint(safe_start, safe_end)
            agent_end_idx = agent_start_idx + obs_window_min

            # 6. æ•°æ®åˆæˆ
            cod_clean = bg_matrix[:, 0] + pollutant_curve

            obs_cod = cod_clean[agent_start_idx: agent_end_idx].copy()
            obs_ph = bg_matrix[agent_start_idx: agent_end_idx, 1].copy()
            obs_do = bg_matrix[agent_start_idx: agent_end_idx, 2].copy()
            obs_vel = U_dynamic[agent_start_idx: agent_end_idx].copy()

            # 7. åº”ç”¨ä¼ æ„Ÿå™¨éç†æƒ³æ¡ä»¶
            [obs_cod, obs_ph, obs_do, obs_vel] = self._apply_sensor_imperfections(
                [obs_cod, obs_ph, obs_do, obs_vel]
            )

            # è®¡ç®—ç›¸å¯¹ä½ç½®
            relative_pos = (agent_start_idx - plume_start) / (plume_duration + 1e-6)

            features = np.vstack([obs_cod, obs_ph, obs_do, obs_vel])

            labels = {
                'distance_km': dist_km,
                'source_mass_kg': mass_mg / 1e6,
                'relative_position': relative_pos,
                'river_width': width
            }

            self.generated_data.append({'features': features, 'labels': labels})
            pbar.update(1)

        pbar.close()
        return self.generated_data

    def save_dataset(self, filename='robust_usv_dataset'):
        """æ ¼å¼åŒ–å¹¶ä¿å­˜ä¸º NPZ"""
        sequences = []
        targets_dist = []
        targets_mass = []
        targets_pos = []

        for sample in self.generated_data:
            sequences.append(sample['features'])
            l = sample['labels']
            targets_dist.append(l['distance_km'])
            targets_mass.append(l['source_mass_kg'])
            targets_pos.append(l['relative_position'])

        # è½¬æ¢ä¸º Numpy æ•°ç»„
        # X: (N, 4, Window_Len)
        X = np.array(sequences)
        # y: å¤šä»»åŠ¡æ ‡ç­¾
        y_dist = np.array(targets_dist)
        y_mass = np.array(targets_mass)
        y_pos = np.array(targets_pos)

        save_path = f'{filename}.npz'
        np.savez_compressed(
            save_path,
            X=X,
            y_dist=y_dist,
            y_mass=y_mass,
            y_pos=y_pos
        )
        print(f"\nâœ¨ æ•°æ®é›†ç”Ÿæˆå®Œæ¯•ï¼å·²ä¿å­˜è‡³: {save_path}")
        print(f"   æ ·æœ¬å½¢çŠ¶ (X): {X.shape}")
        print(f"   åŒ…å«æ ‡ç­¾: è·ç¦» (y_dist), è´¨é‡ (y_mass), ç›¸å¯¹ä½ç½® (y_pos)")


def main():
    # ä½¿ç”¨ç¤ºä¾‹
    try:
        # å®ä¾‹åŒ–æ¨¡æ‹Ÿå™¨
        # ç¡®ä¿å½“å‰ç›®å½•ä¸‹æœ‰ 'station_time_series.pkl'ï¼Œå¦‚æœæ²¡æœ‰ä¼šè‡ªåŠ¨ä½¿ç”¨éšæœºå™ªå£°
        sim = RobustUSVSimulator(pkl_path='station_time_series.pkl')

        # ç”Ÿæˆ 5000 æ¡æ ·æœ¬ç”¨äºæµ‹è¯• (æ­£å¼è·‘å»ºè®® 10ä¸‡+)
        # çª—å£è®¾ä¸º 30 åˆ†é’Ÿ (æ— äººèˆ¹åœ¨è¯¥ç‚¹åœç•™ 30 åˆ†é’Ÿ)
        sim.generate_dataset(n_samples=150000, obs_window_min=30)

        # ä¿å­˜
        sim.save_dataset('train_dataset_v3')

    except Exception as e:
        print(f"âŒ è¿è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()